{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcba90ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lthnhung\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "\u001b[32m2025-08-11 15:26:27.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mPROJ_ROOT path is: D:\\DataLocal\\lthnhung\\My Documents\\GitHub\\Retail-Layout-Optimization-with-ML-Metaheuristics\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Đọc & tiền xử lý dữ liệu cho tối ưu layout.\n",
    "\n",
    "Chức năng chính:\n",
    "- Đọc PPTX và trích xuất vị trí, kích thước hình chữ nhật (mm) + Category\n",
    "- Nhận diện Entrance/Cashier (giữ nguyên vị trí), chỉ lấy các slot bày hàng để tối ưu\n",
    "- Đánh dấu slot lạnh/không lạnh dựa vào danh sách refrigerated_categories\n",
    "- Chuẩn hóa rules (cặp liên quan) + tính support (từ transactions × sku)\n",
    "- Chuẩn bị dữ liệu cho SA (tọa độ slot bày hàng, danh sách category, slot lạnh, …)\n",
    "\n",
    "Nguyên tắc:\n",
    "- KHÔNG sắp xếp Entrance/Cashier.\n",
    "- Các nhóm hàng “lạnh” chỉ được đặt vào slot lạnh; nhóm thường chỉ vào slot thường.\n",
    "\"\"\"\n",
    "\n",
    "import ast\n",
    "import random\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pptx import Presentation\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "from src.config import (\n",
    "    EXTERNAL_DATA_DIR,\n",
    "    RAW_DATA_DIR,\n",
    "    PROCESSED_DATA_DIR,\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Helpers\n",
    "# -----------------\n",
    "def normalize(s: str) -> str:\n",
    "    \"\"\"Chuẩn hóa chuỗi: lower, bỏ dấu, bỏ khoảng trắng đầu/cuối.\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.strip().lower()\n",
    "    return \"\".join(\n",
    "        ch for ch in unicodedata.normalize(\"NFD\", s) if unicodedata.category(ch) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_shapes_from_ppt_mm(ppt_file: Path) -> Tuple[pd.DataFrame, Presentation]:\n",
    "    \"\"\"Đọc tất cả shapes có text từ PPTX, trả về dataframe [x,y,width,height] theo mm.\"\"\"\n",
    "    EMU_PER_MM = 914400 / 25.4\n",
    "    prs = Presentation(ppt_file)\n",
    "    rows = []\n",
    "    for s_idx, slide in enumerate(prs.slides):\n",
    "        for sh_idx, shape in enumerate(slide.shapes):\n",
    "            if not shape.has_text_frame:\n",
    "                continue\n",
    "            txt = (shape.text_frame.text or \"\").strip()\n",
    "            if not txt:\n",
    "                continue\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"slide_idx\": s_idx,\n",
    "                    \"shape_idx\": sh_idx,\n",
    "                    \"shape_obj\": shape,\n",
    "                    \"Category\": txt,\n",
    "                    \"x\": shape.left / EMU_PER_MM,\n",
    "                    \"y\": shape.top / EMU_PER_MM,\n",
    "                    \"width\": shape.width / EMU_PER_MM,\n",
    "                    \"height\": shape.height / EMU_PER_MM,\n",
    "                }\n",
    "            )\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No shapes with text found in PPTX.\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df, prs\n",
    "\n",
    "\n",
    "def rect_center(row: pd.Series) -> Tuple[float, float]:\n",
    "    \"\"\"Tâm hình chữ nhật (mm).\"\"\"\n",
    "    return (row[\"x\"] + row[\"width\"] / 2.0, row[\"y\"] + row[\"height\"] / 2.0)\n",
    "\n",
    "\n",
    "def parse_itemset(cell: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Parse cột antecedent/consequent nếu đôi khi được ghi dạng ['A'].\n",
    "    Trả về 1 string nếu là singleton, ngược lại None.\n",
    "    \"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return None\n",
    "    s = str(cell).strip()\n",
    "    if not (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "        return s if s else None\n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        if isinstance(val, (list, tuple)) and len(val) == 1:\n",
    "            return str(val[0])\n",
    "        return None\n",
    "    except Exception:\n",
    "        inner = s.strip(\"[]\").strip()\n",
    "        parts = [p.strip(\" '\\\"\") for p in inner.split(\",\") if p.strip(\" '\\\"\")]\n",
    "        return parts[0] if len(parts) == 1 else None\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Main loader\n",
    "# -----------------\n",
    "def load_input_data(\n",
    "    layout_pptx: str = \"layout.pptx\",\n",
    "    assoc_rules_csv: str = \"association_rules.csv\",\n",
    "    transactions_csv: str = \"transactions.csv\",\n",
    "    sku_csv: str = \"sku.csv\",\n",
    "    refrigerated_categories: Optional[List[str]] = None,\n",
    "    random_seed: int = 42,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Load + preprocess (PPTX geometry + CSV flags + rules + support).\n",
    "\n",
    "    Quan trọng:\n",
    "    - Nhận diện Entrance/Cashier bằng từ khóa: 'entry', 'entrance' và 'cashier' (bỏ dấu, không phân biệt hoa thường).\n",
    "    - Chỉ các slot bày hàng (không phải Entrance/Cashier) được đưa vào tối ưu.\n",
    "    - slot_is_cold: True nếu slot hiện tại chứa category thuộc danh sách 'refrigerated_categories' (tức vị trí đó là khu lạnh).\n",
    "    - current_assign: ánh xạ Category->slot_idx ban đầu (để làm xuất phát cho SA).\n",
    "    \"\"\"\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    refrigerated_categories = refrigerated_categories or []\n",
    "    refrigerated_norm = {normalize(r) for r in refrigerated_categories}\n",
    "\n",
    "    # 1) PPTX (đúng thư mục layout)\n",
    "    df_ppt, prs = load_shapes_from_ppt_mm(EXTERNAL_DATA_DIR / layout_pptx)\n",
    "    df_ppt[\"cx\"], df_ppt[\"cy\"] = zip(*df_ppt.apply(rect_center, axis=1))\n",
    "\n",
    "    # 2) Flags (Entrance/Cashier/Cold)\n",
    "    def is_entrance_kw(c: str) -> bool:\n",
    "        n = normalize(c)\n",
    "        return n in {\"entry\", \"entrance\"}\n",
    "\n",
    "    def is_cashier_kw(c: str) -> bool:\n",
    "        n = normalize(c)\n",
    "        return n == \"cashier\"\n",
    "\n",
    "    def is_cold_kw(c: str) -> bool:\n",
    "        return normalize(c) in refrigerated_norm\n",
    "\n",
    "    df = df_ppt.copy()\n",
    "    df[\"is_entrance\"] = df[\"Category\"].apply(is_entrance_kw)\n",
    "    df[\"is_cashier\"] = df[\"Category\"].apply(is_cashier_kw)\n",
    "    df[\"is_refrigerated\"] = df[\"Category\"].apply(is_cold_kw)\n",
    "\n",
    "    # 3) Bắt buộc có đúng 1 Entrance & 1 Cashier\n",
    "    if df[\"is_entrance\"].sum() != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Expected exactly one Entrance (entry/entrance), found {df['is_entrance'].sum()}. \"\n",
    "            f\"Check PPTX shape names!\"\n",
    "        )\n",
    "    if df[\"is_cashier\"].sum() != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Expected exactly one Cashier, found {df['is_cashier'].sum()}. \"\n",
    "            f\"Check PPTX shape names!\"\n",
    "        )\n",
    "\n",
    "    entr_xy = (\n",
    "        df.loc[df[\"is_entrance\"], \"cx\"].iloc[0],\n",
    "        df.loc[df[\"is_entrance\"], \"cy\"].iloc[0],\n",
    "    )\n",
    "    cash_xy = (\n",
    "        df.loc[df[\"is_cashier\"], \"cx\"].iloc[0],\n",
    "        df.loc[df[\"is_cashier\"], \"cy\"].iloc[0],\n",
    "    )\n",
    "\n",
    "    # 4) Slots bày hàng = tất cả trừ Entrance/Cashier\n",
    "    slots_mask = ~(df[\"is_entrance\"] | df[\"is_cashier\"])\n",
    "    slots = df.loc[slots_mask].copy()\n",
    "    slots[\"orig_idx\"] = slots.index  # <— thêm dòng này: lưu index gốc trong df\n",
    "    slots = slots.reset_index(drop=True)\n",
    "\n",
    "    slots[\"slot_idx\"] = np.arange(len(slots))\n",
    "    layout_cats = slots[\"Category\"].astype(str).tolist()\n",
    "    # slot_is_cold: slot hiện tại đang là khu lạnh hay không, dựa theo category đang nằm ở đó\n",
    "    slot_is_cold = slots[\"is_refrigerated\"].astype(bool).tolist()\n",
    "\n",
    "    # 5) Association rules (1→1)\n",
    "    rules = pd.read_csv(PROCESSED_DATA_DIR / assoc_rules_csv)\n",
    "    rules[\"_a\"] = rules[\"antecedent\"].apply(parse_itemset)\n",
    "    rules[\"_b\"] = rules[\"consequent\"].apply(parse_itemset)\n",
    "    pairs = rules.dropna(subset=[\"_a\", \"_b\"]).copy()\n",
    "    pairs[\"weight\"] = pairs[\"lift\"] if \"lift\" in pairs.columns else pairs[\"confidence\"]\n",
    "    pairs = pairs[[\"_a\", \"_b\", \"weight\"]].rename(columns={\"_a\": \"cat_a\", \"_b\": \"cat_b\"})\n",
    "    pairs = pairs[pairs[\"cat_a\"].isin(layout_cats) & pairs[\"cat_b\"].isin(layout_cats)]\n",
    "    pairs = pairs[pairs[\"cat_a\"] != pairs[\"cat_b\"]]\n",
    "    pairs = pairs.groupby([\"cat_a\", \"cat_b\"], as_index=False)[\"weight\"].mean()\n",
    "    pairs_list = [\n",
    "        (a, b, w) for a, b, w in zip(pairs[\"cat_a\"], pairs[\"cat_b\"], pairs[\"weight\"])\n",
    "    ]\n",
    "\n",
    "    # 6) Transactions × SKU -> baskets + support\n",
    "    baskets = []\n",
    "    cat_support = {}\n",
    "    try:\n",
    "        tx = pd.read_csv(RAW_DATA_DIR / transactions_csv, usecols=[\"Sku\", \"MergedId\"])\n",
    "        sku = pd.read_csv(RAW_DATA_DIR / sku_csv, usecols=[\"Sku\", \"SDeptName\"])\n",
    "        tx[\"Sku\"] = tx[\"Sku\"].astype(str)\n",
    "        sku[\"Sku\"] = sku[\"Sku\"].astype(str)\n",
    "        sku[\"SDeptName\"] = sku[\"SDeptName\"].astype(str)\n",
    "        tx = tx.merge(sku, on=\"Sku\", how=\"left\").dropna(\n",
    "            subset=[\"SDeptName\", \"MergedId\"]\n",
    "        )\n",
    "        baskets = (\n",
    "            tx.groupby(\"MergedId\")[\"SDeptName\"]\n",
    "            .apply(lambda s: set(map(str, s.unique())))\n",
    "            .tolist()\n",
    "        )\n",
    "        from collections import defaultdict as _dd\n",
    "\n",
    "        cat_counts = _dd(int)\n",
    "        for b in baskets:\n",
    "            for c in b:\n",
    "                cat_counts[c] += 1\n",
    "        n_baskets = max(1, len(baskets))\n",
    "        cat_support = {c: cat_counts.get(c, 0) / n_baskets for c in layout_cats}\n",
    "    except FileNotFoundError:\n",
    "        baskets = []\n",
    "        cat_support = {c: 0.0 for c in layout_cats}\n",
    "\n",
    "    # 7) Dữ liệu cho tối ưu\n",
    "    coords = np.array(list(zip(slots[\"cx\"].values, slots[\"cy\"].values)))\n",
    "    current_assign = {str(r[\"Category\"]): i for i, r in slots.iterrows()}\n",
    "\n",
    "    # Tập category lạnh ở THỜI ĐIỂM BAN ĐẦU (để ràng buộc giữ nhóm lạnh)\n",
    "    cold_cats = set(\n",
    "        str(r[\"Category\"]) for _, r in slots.iterrows() if r[\"is_refrigerated\"]\n",
    "    )\n",
    "\n",
    "    if len(cold_cats) > int(sum(slot_is_cold)):\n",
    "        raise RuntimeError(\n",
    "            f\"Number of refrigerated categories ({len(cold_cats)}) exceeds refrigerated slots ({int(sum(slot_is_cold))}).\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"df\": df,\n",
    "        \"prs\": prs,\n",
    "        \"entr_xy\": entr_xy,\n",
    "        \"cash_xy\": cash_xy,\n",
    "        \"slots\": slots,\n",
    "        \"layout_cats\": layout_cats,\n",
    "        \"slot_is_cold\": slot_is_cold,\n",
    "        \"pairs_list\": pairs_list,\n",
    "        \"cat_support\": cat_support,\n",
    "        \"coords\": coords,\n",
    "        \"current_assign\": current_assign,\n",
    "        \"cold_cats\": cold_cats,\n",
    "        \"baskets\": baskets,\n",
    "    }\n",
    "\n",
    "\n",
    "refrigerated_categories = [\n",
    "    \"Thit dong lanh\",\n",
    "    \"Tau hu cac loai\",\n",
    "    \"Kem cac loai\",\n",
    "    \"Tru mat khac (FLAN)\",\n",
    "    \"San pham che bien d.lanh\",\n",
    "    \"Com, xoi dong lanh\",\n",
    "    \"Rau,cu,trai cay dong lanh\",\n",
    "    \"Cha gio\",\n",
    "    \"San pham ch.bien dong goi\",\n",
    "    \"Hai san dong lanh\",\n",
    "]\n",
    "\n",
    "input_data = load_input_data(\n",
    "    layout_pptx=\"layout.pptx\",\n",
    "    assoc_rules_csv=\"association_rules.csv\",\n",
    "    transactions_csv=\"transactions.csv\",\n",
    "    sku_csv=\"sku.csv\",\n",
    "    refrigerated_categories=refrigerated_categories,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, random, unicodedata\n",
    "import numpy as np, pandas as pd\n",
    "from pptx import Presentation\n",
    "from pathlib import Path\n",
    "from src.config import (\n",
    "    EXTERNAL_DATA_DIR,\n",
    "    INTERIM_DATA_DIR,\n",
    "    RAW_DATA_DIR,\n",
    "    PROCESSED_DATA_DIR,\n",
    ")\n",
    "\n",
    "\n",
    "def load_input_data(\n",
    "    layout_pptx=\"layout.pptx\",\n",
    "    assoc_rules_csv=\"association_rules.csv\",\n",
    "    transactions_csv=\"transactions.csv\",\n",
    "    sku_csv=\"sku.csv\",\n",
    "    refrigerated_categories=None,\n",
    "    random_seed=42,\n",
    "):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    refrigerated_categories = refrigerated_categories or []\n",
    "    normalize = lambda s: (\n",
    "        \"\"\n",
    "        if s is None\n",
    "        else \"\".join(\n",
    "            ch\n",
    "            for ch in unicodedata.normalize(\"NFD\", s.strip().lower())\n",
    "            if unicodedata.category(ch) != \"Mn\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 1) Đọc PPTX -> mm\n",
    "    EMU_PER_MM = 914400 / 25.4\n",
    "    prs = Presentation(EXTERNAL_DATA_DIR / layout_pptx)\n",
    "    rows = []\n",
    "    for s_idx, slide in enumerate(prs.slides):\n",
    "        for sh_idx, sh in enumerate(slide.shapes):\n",
    "            if getattr(sh, \"has_text_frame\", False):\n",
    "                txt = (sh.text_frame.text or \"\").strip()\n",
    "                if txt:\n",
    "                    rows.append(\n",
    "                        {\n",
    "                            \"slide_idx\": s_idx,\n",
    "                            \"shape_idx\": sh_idx,\n",
    "                            \"shape_obj\": sh,\n",
    "                            \"Category\": txt,\n",
    "                            \"x\": sh.left / EMU_PER_MM,\n",
    "                            \"y\": sh.top / EMU_PER_MM,\n",
    "                            \"width\": sh.width / EMU_PER_MM,\n",
    "                            \"height\": sh.height / EMU_PER_MM,\n",
    "                        }\n",
    "                    )\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No shapes with text found in PPTX.\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"cx\"] = df[\"x\"] + df[\"width\"] / 2\n",
    "    df[\"cy\"] = df[\"y\"] + df[\"height\"] / 2\n",
    "\n",
    "    # 2) Flags: Entrance/Cashier/Cold\n",
    "    cold_set = {normalize(c) for c in refrigerated_categories}\n",
    "    df[\"is_entrance\"] = df[\"Category\"].map(\n",
    "        lambda c: normalize(c) in {\"entry\", \"entrance\"}\n",
    "    )\n",
    "    df[\"is_cashier\"] = df[\"Category\"].map(lambda c: normalize(c) == \"cashier\")\n",
    "    df[\"is_refrigerated\"] = df[\"Category\"].map(lambda c: normalize(c) in cold_set)\n",
    "\n",
    "    if df[\"is_entrance\"].sum() != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Expected exactly one Entrance, found {df['is_entrance'].sum()}.\"\n",
    "        )\n",
    "    if df[\"is_cashier\"].sum() != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Expected exactly one Cashier, found {df['is_cashier'].sum()}.\"\n",
    "        )\n",
    "\n",
    "    # 3) Slots bày hàng (loại Entrance/Cashier)\n",
    "    slots = df.loc[~(df[\"is_entrance\"] | df[\"is_cashier\"])].copy()\n",
    "    slots[\"orig_idx\"] = slots.index\n",
    "    slots = slots.reset_index(drop=True)\n",
    "    slots[\"slot_idx\"] = np.arange(len(slots))\n",
    "    layout_cats = slots[\"Category\"].astype(str).tolist()\n",
    "    slot_is_cold = slots[\"is_refrigerated\"].astype(bool).tolist()\n",
    "\n",
    "    # 4) Association rules 1→1 (lọc theo layout + weight)\n",
    "    rules = pd.read_csv(INTERIM_DATA_DIR / assoc_rules_csv)\n",
    "\n",
    "    def _to_single(x):\n",
    "        s = str(x).strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                v = ast.literal_eval(s)\n",
    "                return (\n",
    "                    str(v[0]) if isinstance(v, (list, tuple)) and len(v) == 1 else None\n",
    "                )\n",
    "            except Exception:\n",
    "                inner = [\n",
    "                    p.strip(\" '\\\"\") for p in s.strip(\"[]\").split(\",\") if p.strip(\" '\\\"\")\n",
    "                ]\n",
    "                return inner[0] if len(inner) == 1 else None\n",
    "        return s if s else None\n",
    "\n",
    "    pairs = rules.assign(\n",
    "        _a=rules[\"antecedent\"].map(_to_single), _b=rules[\"consequent\"].map(_to_single)\n",
    "    ).dropna(subset=[\"_a\", \"_b\"])\n",
    "    wcol = \"lift\" if \"lift\" in pairs.columns else \"confidence\"\n",
    "    pairs = (\n",
    "        pairs.rename(columns={\"_a\": \"cat_a\", \"_b\": \"cat_b\"})[[\"cat_a\", \"cat_b\", wcol]]\n",
    "        .query(\"cat_a!=cat_b\")\n",
    "        .query(\"cat_a in @layout_cats and cat_b in @layout_cats\")\n",
    "        .groupby([\"cat_a\", \"cat_b\"], as_index=False)[wcol]\n",
    "        .mean()\n",
    "        .rename(columns={wcol: \"weight\"})\n",
    "    )\n",
    "\n",
    "    # 5) Transactions×SKU -> baskets + support\n",
    "    try:\n",
    "        tx = pd.read_csv(\n",
    "            RAW_DATA_DIR / transactions_csv, usecols=[\"Sku\", \"MergedId\"]\n",
    "        ).astype({\"Sku\": str})\n",
    "        sku = pd.read_csv(RAW_DATA_DIR / sku_csv, usecols=[\"Sku\", \"SDeptName\"]).astype(\n",
    "            {\"Sku\": str, \"SDeptName\": str}\n",
    "        )\n",
    "        tx = tx.merge(sku, on=\"Sku\", how=\"left\").dropna(\n",
    "            subset=[\"SDeptName\", \"MergedId\"]\n",
    "        )\n",
    "        baskets = (\n",
    "            tx.groupby(\"MergedId\")[\"SDeptName\"]\n",
    "            .apply(lambda s: set(map(str, s.unique())))\n",
    "            .tolist()\n",
    "        )\n",
    "        from collections import defaultdict as _dd\n",
    "\n",
    "        counts = _dd(int)\n",
    "        for b in baskets:\n",
    "            for c in b:\n",
    "                counts[c] += 1\n",
    "        n = max(1, len(baskets))\n",
    "    except FileNotFoundError:\n",
    "        baskets = []\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Ví dụ dùng:\n",
    "refrigerated_categories = [\n",
    "    \"Thit dong lanh\",\n",
    "    \"Tau hu cac loai\",\n",
    "    \"Kem cac loai\",\n",
    "    \"Tru mat khac (FLAN)\",\n",
    "    \"San pham che bien d.lanh\",\n",
    "    \"Com, xoi dong lanh\",\n",
    "    \"Rau,cu,trai cay dong lanh\",\n",
    "    \"Cha gio\",\n",
    "    \"San pham ch.bien dong goi\",\n",
    "    \"Hai san dong lanh\",\n",
    "]\n",
    "df = load_input_data(\n",
    "    \"layout.pptx\",\n",
    "    \"association_rules.csv\",\n",
    "    \"transactions.csv\",\n",
    "    \"sku.csv\",\n",
    "    refrigerated_categories,\n",
    "    random_seed=42,\n",
    ")\n",
    "df.to_csv(INTERIM_DATA_DIR / \"layout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1ab1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Thuật toán tối ưu (Simulated Annealing) cho việc hoán đổi category giữa các slot bày hàng.\n",
    "\n",
    "Nguyên tắc:\n",
    "- KHÔNG bao gồm Entrance/Cashier trong tập tối ưu.\n",
    "- Chỉ hoán đổi TRONG CÙNG NHÓM:\n",
    "    + Nhóm lạnh (category ∈ cold_cats) chỉ hoán đổi giữa các slot lạnh (slot_is_cold=True).\n",
    "    + Nhóm thường (category ∉ cold_cats) chỉ hoán đổi giữa các slot thường (slot_is_cold=False).\n",
    "- Mục tiêu: kết hợp chi phí cặp (từ rules, khoảng cách Euclid) + khoảng cách tới Entrance (có trọng số theo support).\n",
    "\n",
    "Việc “chỉ swap trong cùng nhóm” đảm bảo 2 nhóm được sắp xếp cùng nhau và không trộn lẫn.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Set\n",
    "\n",
    "# Trọng số mục tiêu + tham số SA\n",
    "ALPHA_PAIR = 1.0\n",
    "BETA_ENTRANCE = 1.0\n",
    "GAMMA_SUPPORT = 0.7\n",
    "SA_ITERS = 8000\n",
    "SA_START_TEMP = 1.0\n",
    "SA_END_TEMP = 0.01\n",
    "\n",
    "\n",
    "def euclid(p: Tuple[float, float], q: Tuple[float, float]) -> float:\n",
    "    return math.hypot(p[0] - q[0], p[1] - q[1])\n",
    "\n",
    "\n",
    "def objective(\n",
    "    assign_map: Dict[str, int],\n",
    "    pairs_list: List[Tuple[str, str, float]],\n",
    "    cat_support: Dict[str, float],\n",
    "    coords: np.ndarray,\n",
    "    entr_xy: Tuple[float, float],\n",
    "    mean_dist: float,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Hàm mục tiêu = ALPHA_PAIR * (chi phí cặp) + BETA_ENTRANCE * (chi phí khoảng cách tới Entrance có trọng số support).\n",
    "    Chuẩn hóa theo mean_dist để ổn định scale.\n",
    "    \"\"\"\n",
    "    # 1) Chi phí cặp (càng gần càng tốt)\n",
    "    pair_cost = 0.0\n",
    "    for a, b, w in pairs_list:\n",
    "        ia = assign_map.get(a)\n",
    "        ib = assign_map.get(b)\n",
    "        if ia is None or ib is None:\n",
    "            continue\n",
    "        pair_cost += w * euclid(coords[ia], coords[ib])\n",
    "    pair_cost = pair_cost / max(1e-9, mean_dist)\n",
    "\n",
    "    # 2) Chi phí Entrance (dựa support^GAMMA_SUPPORT)\n",
    "    ent_cost = 0.0\n",
    "    for c in assign_map:\n",
    "        s = (cat_support.get(c, 0.0)) ** GAMMA_SUPPORT\n",
    "        ent_cost += s * euclid(entr_xy, coords[assign_map[c]])\n",
    "    ent_cost = ent_cost / max(1e-9, mean_dist * len(assign_map))\n",
    "\n",
    "    return ALPHA_PAIR * pair_cost + BETA_ENTRANCE * ent_cost\n",
    "\n",
    "\n",
    "def is_feasible(\n",
    "    assign_map: Dict[str, int], slot_is_cold: List[bool], cold_cats: Set[str]\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Hợp lệ nếu:\n",
    "    - slot lạnh chỉ chứa cat lạnh, slot thường chỉ chứa cat thường\n",
    "    - không trùng slot\n",
    "    \"\"\"\n",
    "    used = set()\n",
    "    for c in assign_map:\n",
    "        si = assign_map[c]\n",
    "        if slot_is_cold[si] and c not in cold_cats:\n",
    "            return False\n",
    "        if (not slot_is_cold[si]) and c in cold_cats:\n",
    "            return False\n",
    "        if si in used:\n",
    "            return False\n",
    "        used.add(si)\n",
    "    return True\n",
    "\n",
    "\n",
    "def simulated_annealing(input_data: Dict) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Tối ưu ánh xạ Category->slot_idx cho CÁC SLOT BÀY HÀNG (Entrance/Cashier không tham gia).\n",
    "    Swap chỉ thực hiện TRONG cùng nhóm (lạnh↔lạnh, thường↔thường).\n",
    "    \"\"\"\n",
    "    coords = input_data[\"coords\"]\n",
    "    pairs_list = input_data[\"pairs_list\"]\n",
    "    cat_support = input_data[\"cat_support\"]\n",
    "    entr_xy = input_data[\"entr_xy\"]\n",
    "    layout_cats = input_data[\"layout_cats\"]\n",
    "    slot_is_cold = input_data[\"slot_is_cold\"]\n",
    "    cold_cats = input_data[\"cold_cats\"]\n",
    "    current_assign = input_data[\"current_assign\"]\n",
    "\n",
    "    # Tính mean_dist để scale objective\n",
    "    if len(coords) >= 2:\n",
    "        rand_idx = np.random.choice(\n",
    "            len(coords), size=(min(500, len(coords) * 2), 2), replace=True\n",
    "        )\n",
    "        mean_dist = np.mean([euclid(coords[i], coords[j]) for i, j in rand_idx])\n",
    "    else:\n",
    "        mean_dist = 1.0\n",
    "\n",
    "    # Tách danh sách category theo nhóm (dựa trên cold_cats)\n",
    "    cold_cat_list = [c for c in layout_cats if c in cold_cats]\n",
    "    warm_cat_list = [c for c in layout_cats if c not in cold_cats]\n",
    "\n",
    "    def temperature(t: int) -> float:\n",
    "        frac = t / max(1, SA_ITERS - 1)\n",
    "        return SA_START_TEMP * (SA_END_TEMP / SA_START_TEMP) ** frac\n",
    "\n",
    "    assign = current_assign.copy()\n",
    "    curr_cost = objective(assign, pairs_list, cat_support, coords, entr_xy, mean_dist)\n",
    "    best_assign = assign.copy()\n",
    "    best_cost = curr_cost\n",
    "\n",
    "    for t in range(SA_ITERS):\n",
    "        T = temperature(t)\n",
    "\n",
    "        # Chọn nhóm để swap (50-50 giữa lạnh/thường, nếu nhóm rỗng thì chọn nhóm còn lại)\n",
    "        if cold_cat_list and warm_cat_list:\n",
    "            use_cold = random.random() < 0.5\n",
    "        elif cold_cat_list:\n",
    "            use_cold = True\n",
    "        elif warm_cat_list:\n",
    "            use_cold = False\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        group = cold_cat_list if use_cold else warm_cat_list\n",
    "        if len(group) < 2:\n",
    "            continue  # không đủ phần tử để swap\n",
    "\n",
    "        a, b = random.sample(group, 2)\n",
    "        ia, ib = assign[a], assign[b]\n",
    "\n",
    "        # Vì đã chọn cùng nhóm, 2 slot này mặc định phải có cùng loại (lạnh/thường)\n",
    "        # nhưng vẫn kiểm tra để an toàn (phòng dữ liệu cũ bất nhất)\n",
    "        if slot_is_cold[ia] != slot_is_cold[ib]:\n",
    "            continue\n",
    "\n",
    "        # Thử swap\n",
    "        assign[a], assign[b] = ib, ia\n",
    "        if not is_feasible(assign, slot_is_cold, cold_cats):\n",
    "            assign[a], assign[b] = ia, ib\n",
    "            continue\n",
    "\n",
    "        new_cost = objective(\n",
    "            assign, pairs_list, cat_support, coords, entr_xy, mean_dist\n",
    "        )\n",
    "        delta = new_cost - curr_cost\n",
    "        if (delta < 0) or (random.random() < math.exp(-delta / max(1e-9, T))):\n",
    "            curr_cost = new_cost\n",
    "            if new_cost < best_cost:\n",
    "                best_cost = new_cost\n",
    "                best_assign = assign.copy()\n",
    "        else:\n",
    "            # hoàn tác nếu không chấp nhận\n",
    "            assign[a], assign[b] = ia, ib\n",
    "\n",
    "    return best_assign\n",
    "\n",
    "\n",
    "assign_map = simulated_annealing(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593c3f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedVariableError",
     "evalue": "local variable 'layout_cats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\scope.py:227\u001b[39m, in \u001b[36mScope.resolve\u001b[39m\u001b[34m(self, key, is_local)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# not a local variable so check in resolvers if we have them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py:1006\u001b[39m, in \u001b[36mChainMap.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1005\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__missing__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py:998\u001b[39m, in \u001b[36mChainMap.__missing__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__missing__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'layout_cats'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\scope.py:242\u001b[39m, in \u001b[36mScope.resolve\u001b[39m\u001b[34m(self, key, is_local)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# last ditch effort we look in temporaries\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# these are created when parsing indexing expressions\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# e.g., df[df > 0]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mKeyError\u001b[39m: 'layout_cats'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mUndefinedVariableError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 144\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# Ví dụ dùng:\u001b[39;00m\n\u001b[32m    132\u001b[39m refrigerated_categories = [\n\u001b[32m    133\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThit dong lanh\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    134\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTau hu cac loai\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    142\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mHai san dong lanh\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    143\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m df = \u001b[43mload_input_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayout.pptx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massociation_rules.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtransactions.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msku.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrefrigerated_categories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mload_input_data\u001b[39m\u001b[34m(layout_pptx, assoc_rules_csv, transactions_csv, sku_csv, refrigerated_categories, random_seed)\u001b[39m\n\u001b[32m     90\u001b[39m pairs = rules.assign(\n\u001b[32m     91\u001b[39m     _a=rules[\u001b[33m\"\u001b[39m\u001b[33mantecedent\u001b[39m\u001b[33m\"\u001b[39m].map(_to_single), _b=rules[\u001b[33m\"\u001b[39m\u001b[33mconsequent\u001b[39m\u001b[33m\"\u001b[39m].map(_to_single)\n\u001b[32m     92\u001b[39m ).dropna(subset=[\u001b[33m\"\u001b[39m\u001b[33m_a\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_b\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     93\u001b[39m wcol = \u001b[33m\"\u001b[39m\u001b[33mlift\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlift\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pairs.columns \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m pairs = (\n\u001b[32m     95\u001b[39m     \u001b[43mpairs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcat_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcat_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcat_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcat_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcat_a!=cat_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcat_a in @layout_cats and cat_b in @layout_cats\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     .groupby([\u001b[33m\"\u001b[39m\u001b[33mcat_a\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcat_b\u001b[39m\u001b[33m\"\u001b[39m], as_index=\u001b[38;5;28;01mFalse\u001b[39;00m)[wcol]\n\u001b[32m     99\u001b[39m     .mean()\n\u001b[32m    100\u001b[39m     .rename(columns={wcol: \u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    101\u001b[39m )\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# 5) Transactions×SKU -> baskets + support\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4828\u001b[39m, in \u001b[36mDataFrame.query\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4826\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) + \u001b[32m1\u001b[39m\n\u001b[32m   4827\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4828\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4830\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4831\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.loc[res]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[39m, in \u001b[36mDataFrame.eval\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4951\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   4952\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mtuple\u001b[39m(kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m, ())) + resolvers\n\u001b[32m-> \u001b[39m\u001b[32m4954\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\eval.py:339\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(expr, parser, engine, local_dict, global_dict, resolvers, level, target, inplace)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[32m    331\u001b[39m env = ensure_scope(\n\u001b[32m    332\u001b[39m     level + \u001b[32m1\u001b[39m,\n\u001b[32m    333\u001b[39m     global_dict=global_dict,\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m     target=target,\n\u001b[32m    337\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m parsed_expr = \u001b[43mExpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mnumexpr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    342\u001b[39m     (\n\u001b[32m    343\u001b[39m         is_extension_array_dtype(parsed_expr.terms.return_type)\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m     )\n\u001b[32m    351\u001b[39m ):\n\u001b[32m    352\u001b[39m     warnings.warn(\n\u001b[32m    353\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine has switched to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m\u001b[33m because numexpr does not support \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    354\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mextension array dtypes. Please set your engine to python manually.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[32m    356\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    357\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:809\u001b[39m, in \u001b[36mExpr.__init__\u001b[39m\u001b[34m(self, expr, engine, parser, env, level)\u001b[39m\n\u001b[32m    807\u001b[39m \u001b[38;5;28mself\u001b[39m.parser = parser\n\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m._visitor = PARSERS[parser](\u001b[38;5;28mself\u001b[39m.env, \u001b[38;5;28mself\u001b[39m.engine, \u001b[38;5;28mself\u001b[39m.parser)\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m \u001b[38;5;28mself\u001b[39m.terms = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:828\u001b[39m, in \u001b[36mExpr.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    825\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[33;03m    Parse an expression.\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_visitor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:419\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Module\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33monly a single expression is allowed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    418\u001b[39m expr = node.body[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:422\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Expr\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisit_Expr\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:746\u001b[39m, in \u001b[36mBaseExprVisitor.visit_BoolOp\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._maybe_evaluate_binop(op, node.op, lhs, rhs)\n\u001b[32m    745\u001b[39m operands = node.values\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:739\u001b[39m, in \u001b[36mBaseExprVisitor.visit_BoolOp.<locals>.visitor\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisitor\u001b[39m(x, y):\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     lhs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_visit_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m     rhs = \u001b[38;5;28mself\u001b[39m._try_visit_binop(y)\n\u001b[32m    742\u001b[39m     op, op_class, lhs, rhs = \u001b[38;5;28mself\u001b[39m._maybe_transform_eq_ne(node, lhs, rhs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:735\u001b[39m, in \u001b[36mBaseExprVisitor._try_visit_binop\u001b[39m\u001b[34m(self, bop)\u001b[39m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bop, (Op, Term)):\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bop\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbop\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:719\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Compare\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m     op = \u001b[38;5;28mself\u001b[39m.translate_In(ops[\u001b[32m0\u001b[39m])\n\u001b[32m    718\u001b[39m     binop = ast.BinOp(op=op, left=node.left, right=comps[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;66;03m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[39;00m\n\u001b[32m    722\u001b[39m left = node.left\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:535\u001b[39m, in \u001b[36mBaseExprVisitor.visit_BinOp\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisit_BinOp\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     op, op_class, left, right = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_transform_eq_ne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m     left, right = \u001b[38;5;28mself\u001b[39m._maybe_downcast_constants(left, right)\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._maybe_evaluate_binop(op, op_class, left, right)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:455\u001b[39m, in \u001b[36mBaseExprVisitor._maybe_transform_eq_ne\u001b[39m\u001b[34m(self, node, left, right)\u001b[39m\n\u001b[32m    453\u001b[39m     left = \u001b[38;5;28mself\u001b[39m.visit(node.left, side=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     right = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mright\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m op, op_class, left, right = \u001b[38;5;28mself\u001b[39m._rewrite_membership_op(node, left, right)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op, op_class, left, right\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expr.py:545\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Name\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisit_Name\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, **kwargs) -> Term:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mterm_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\ops.py:91\u001b[39m, in \u001b[36mTerm.__init__\u001b[39m\u001b[34m(self, name, env, side, encoding)\u001b[39m\n\u001b[32m     89\u001b[39m tname = \u001b[38;5;28mstr\u001b[39m(name)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mself\u001b[39m.is_local = tname.startswith(LOCAL_TAG) \u001b[38;5;129;01mor\u001b[39;00m tname \u001b[38;5;129;01min\u001b[39;00m DEFAULT_GLOBALS\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28mself\u001b[39m._value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_resolve_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.encoding = encoding\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\ops.py:115\u001b[39m, in \u001b[36mTerm._resolve_name\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.scope \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m.env.scope[local_name], \u001b[38;5;28mtype\u001b[39m\n\u001b[32m    112\u001b[39m ):\n\u001b[32m    113\u001b[39m     is_local = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_local\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.update(res)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m res.ndim > \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinh-nt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\scope.py:244\u001b[39m, in \u001b[36mScope.resolve\u001b[39m\u001b[34m(self, key, is_local)\u001b[39m\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.temps[key]\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UndefinedVariableError(key, is_local) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mUndefinedVariableError\u001b[39m: local variable 'layout_cats' is not defined"
     ]
    }
   ],
   "source": [
    "def load_input_data(\n",
    "    layout_pptx=\"layout.pptx\",\n",
    "    assoc_rules_csv=\"association_rules.csv\",\n",
    "    transactions_csv=\"transactions.csv\",\n",
    "    sku_csv=\"sku.csv\",\n",
    "    refrigerated_categories=None,\n",
    "    random_seed=42,\n",
    "):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    refrigerated_categories = refrigerated_categories or []\n",
    "    normalize = lambda s: (\n",
    "        \"\"\n",
    "        if s is None\n",
    "        else \"\".join(\n",
    "            ch\n",
    "            for ch in unicodedata.normalize(\"NFD\", s.strip().lower())\n",
    "            if unicodedata.category(ch) != \"Mn\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 1) Đọc PPTX -> mm\n",
    "    EMU_PER_MM = 914400 / 25.4\n",
    "    prs = Presentation(EXTERNAL_DATA_DIR / layout_pptx)\n",
    "    rows = []\n",
    "    for s_idx, slide in enumerate(prs.slides):\n",
    "        for sh_idx, sh in enumerate(slide.shapes):\n",
    "            if getattr(sh, \"has_text_frame\", False):\n",
    "                txt = (sh.text_frame.text or \"\").strip()\n",
    "                if txt:\n",
    "                    rows.append(\n",
    "                        {\n",
    "                            \"slide_idx\": s_idx,\n",
    "                            \"shape_idx\": sh_idx,\n",
    "                            \"shape_obj\": sh,\n",
    "                            \"Category\": txt,\n",
    "                            \"x\": sh.left / EMU_PER_MM,\n",
    "                            \"y\": sh.top / EMU_PER_MM,\n",
    "                            \"width\": sh.width / EMU_PER_MM,\n",
    "                            \"height\": sh.height / EMU_PER_MM,\n",
    "                        }\n",
    "                    )\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No shapes with text found in PPTX.\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"cx\"] = df[\"x\"] + df[\"width\"] / 2\n",
    "    df[\"cy\"] = df[\"y\"] + df[\"height\"] / 2\n",
    "\n",
    "    # 2) Flags: Entrance/Cashier/Cold\n",
    "    cold_set = {normalize(c) for c in refrigerated_categories}\n",
    "    df[\"is_entrance\"] = df[\"Category\"].map(\n",
    "        lambda c: normalize(c) in {\"entry\", \"entrance\"}\n",
    "    )\n",
    "    df[\"is_cashier\"] = df[\"Category\"].map(lambda c: normalize(c) == \"cashier\")\n",
    "    df[\"is_refrigerated\"] = df[\"Category\"].map(lambda c: normalize(c) in cold_set)\n",
    "\n",
    "    if df[\"is_entrance\"].sum() != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Expected exactly one Entrance, found {df['is_entrance'].sum()}.\"\n",
    "        )\n",
    "    if df[\"is_cashier\"].sum() != 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Expected exactly one Cashier, found {df['is_cashier'].sum()}.\"\n",
    "        )\n",
    "\n",
    "    # 3) Slots bày hàng (loại Entrance/Cashier)\n",
    "    slots = df.loc[~(df[\"is_entrance\"] | df[\"is_cashier\"])].copy()\n",
    "    slots[\"orig_idx\"] = slots.index\n",
    "    slots = slots.reset_index(drop=True)\n",
    "    slots[\"slot_idx\"] = np.arange(len(slots))\n",
    "\n",
    "    # 4) Association rules 1→1 (lọc theo layout + weight)\n",
    "    rules = pd.read_csv(INTERIM_DATA_DIR / assoc_rules_csv)\n",
    "\n",
    "    def _to_single(x):\n",
    "        s = str(x).strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                v = ast.literal_eval(s)\n",
    "                return (\n",
    "                    str(v[0]) if isinstance(v, (list, tuple)) and len(v) == 1 else None\n",
    "                )\n",
    "            except Exception:\n",
    "                inner = [\n",
    "                    p.strip(\" '\\\"\") for p in s.strip(\"[]\").split(\",\") if p.strip(\" '\\\"\")\n",
    "                ]\n",
    "                return inner[0] if len(inner) == 1 else None\n",
    "        return s if s else None\n",
    "\n",
    "    pairs = rules.assign(\n",
    "        _a=rules[\"antecedent\"].map(_to_single), _b=rules[\"consequent\"].map(_to_single)\n",
    "    ).dropna(subset=[\"_a\", \"_b\"])\n",
    "    wcol = \"lift\" if \"lift\" in pairs.columns else \"confidence\"\n",
    "    pairs = (\n",
    "        pairs.rename(columns={\"_a\": \"cat_a\", \"_b\": \"cat_b\"})[[\"cat_a\", \"cat_b\", wcol]]\n",
    "        .query(\"cat_a!=cat_b\")\n",
    "        .query(\"cat_a in @layout_cats and cat_b in @layout_cats\")\n",
    "        .groupby([\"cat_a\", \"cat_b\"], as_index=False)[wcol]\n",
    "        .mean()\n",
    "        .rename(columns={wcol: \"weight\"})\n",
    "    )\n",
    "\n",
    "    # 5) Transactions×SKU -> baskets + support\n",
    "    try:\n",
    "        tx = pd.read_csv(\n",
    "            RAW_DATA_DIR / transactions_csv, usecols=[\"Sku\", \"MergedId\"]\n",
    "        ).astype({\"Sku\": str})\n",
    "        sku = pd.read_csv(RAW_DATA_DIR / sku_csv, usecols=[\"Sku\", \"SDeptName\"]).astype(\n",
    "            {\"Sku\": str, \"SDeptName\": str}\n",
    "        )\n",
    "        tx = tx.merge(sku, on=\"Sku\", how=\"left\").dropna(\n",
    "            subset=[\"SDeptName\", \"MergedId\"]\n",
    "        )\n",
    "        baskets = (\n",
    "            tx.groupby(\"MergedId\")[\"SDeptName\"]\n",
    "            .apply(lambda s: set(map(str, s.unique())))\n",
    "            .tolist()\n",
    "        )\n",
    "        from collections import defaultdict as _dd\n",
    "\n",
    "        counts = _dd(int)\n",
    "        for b in baskets:\n",
    "            for c in b:\n",
    "                counts[c] += 1\n",
    "    except FileNotFoundError:\n",
    "        baskets = []\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Ví dụ dùng:\n",
    "refrigerated_categories = [\n",
    "    \"Thit dong lanh\",\n",
    "    \"Tau hu cac loai\",\n",
    "    \"Kem cac loai\",\n",
    "    \"Tru mat khac (FLAN)\",\n",
    "    \"San pham che bien d.lanh\",\n",
    "    \"Com, xoi dong lanh\",\n",
    "    \"Rau,cu,trai cay dong lanh\",\n",
    "    \"Cha gio\",\n",
    "    \"San pham ch.bien dong goi\",\n",
    "    \"Hai san dong lanh\",\n",
    "]\n",
    "df = load_input_data(\n",
    "    \"layout.pptx\",\n",
    "    \"association_rules.csv\",\n",
    "    \"transactions.csv\",\n",
    "    \"sku.csv\",\n",
    "    refrigerated_categories,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9a23b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lthnhung\\AppData\\Local\\Temp\\ipykernel_69784\\1021450154.py:120: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.cm.get_cmap(\"tab20\", max(1, max_id))(i) for i in range(max_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path length: 297.61\n",
      "New path length: 289.81\n",
      "Improvement: 2.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lthnhung\\AppData\\Local\\Temp\\ipykernel_69784\\1021450154.py:188: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = plt.cm.get_cmap(\"tab20\", max(1, len(cats)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'df_new':     slide_idx  shape_idx                                          shape_obj  \\\n",
       " 0           0          0  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 1           0          1  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 2           0          2  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 3           0          3  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 4           0          4  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " ..        ...        ...                                                ...   \n",
       " 64          0         64  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 65          0         65  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 66          0         66  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 67          0         67  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " 68          0         68  <pptx.shapes.autoshape.Shape object at 0x00000...   \n",
       " \n",
       "                      Category           x           y      width     height  \\\n",
       " 0                        Muoi   54.795639  296.875528  29.360889   2.333306   \n",
       " 1                   Nuoc ngot   70.832361  282.236889  13.142500   2.834944   \n",
       " 2                 Hang do hop   74.119028  236.176361  10.037528   2.287056   \n",
       " 3                Giay ve sinh   40.955028  234.441333   2.559778  13.807972   \n",
       " 4   VSinh nha, thiet bi(choi)   51.718889  311.723667   2.463444   5.420389   \n",
       " ..                        ...         ...         ...        ...        ...   \n",
       " 64               Sua cac loai  123.258944  169.530250   9.451167   2.822222   \n",
       " 65           San pham ve sinh  113.226944  169.530250  10.031972   2.822222   \n",
       " 66                   Entrance  120.783694   85.878139  16.389444   4.274667   \n",
       " 67                    Cashier  121.542056  106.598222  14.872722   6.493306   \n",
       " 68                  Nuoc uong   54.407778   75.123778   2.504028  14.618417   \n",
       " \n",
       "             cx          cy  is_entrance  is_cashier  is_refrigerated  \n",
       " 0    69.476083  298.042181        False       False            False  \n",
       " 1    77.403611  283.654361        False       False            False  \n",
       " 2    79.137792  237.319889        False       False            False  \n",
       " 3    42.234917  241.345319        False       False            False  \n",
       " 4    52.950611  314.433861        False       False            False  \n",
       " ..         ...         ...          ...         ...              ...  \n",
       " 64  127.984528  170.941361        False       False            False  \n",
       " 65  118.242931  170.941361        False       False            False  \n",
       " 66  128.978417   88.015472         True       False            False  \n",
       " 67  128.978417  109.844875        False        True            False  \n",
       " 68   55.659792   82.432986        False       False            False  \n",
       " \n",
       " [69 rows x 13 columns],\n",
       " 'base_length': 297.61107122222217,\n",
       " 'new_length': 289.81083877777775,\n",
       " 'improvement': 2.62094834456615}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lưu kết quả + trực quan:\n",
    "- Cập nhật Category mới CHO CÁC SLOT BÀY HÀNG theo mapping tối ưu (Entrance/Cashier giữ nguyên)\n",
    "- Xuất CSV, PNG (preview dạng grid), và PPTX đã thay nhãn & màu cho slot bày hàng\n",
    "- Benchmark chiều dài đường đi (Manhattan, greedy từ Entrance đến Cashier)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from pptx import Presentation\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.util import Pt\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "import math\n",
    "\n",
    "from src.config import OUTPUT_DATA_DIR\n",
    "\n",
    "PADDING_RATIO = 0.06\n",
    "\n",
    "\n",
    "def manhattan(p: Tuple[float, float], q: Tuple[float, float]) -> float:\n",
    "    return abs(p[0] - q[0]) + abs(p[1] - q[1])\n",
    "\n",
    "\n",
    "def greedy_path_length(\n",
    "    points: List[Tuple[float, float]],\n",
    "    start: Tuple[float, float],\n",
    "    end: Tuple[float, float],\n",
    "    dist_fn=manhattan,\n",
    ") -> float:\n",
    "    \"\"\"Tính độ dài đường đi kiểu tham lam: từ start đi qua các điểm rồi đến end.\"\"\"\n",
    "    if not points:\n",
    "        return dist_fn(start, end)\n",
    "    unvisited = points[:]\n",
    "    cur = start\n",
    "    total = 0.0\n",
    "    while unvisited:\n",
    "        nxt_i = min(range(len(unvisited)), key=lambda i: dist_fn(cur, unvisited[i]))\n",
    "        nxt = unvisited.pop(nxt_i)\n",
    "        total += dist_fn(cur, nxt)\n",
    "        cur = nxt\n",
    "    total += dist_fn(cur, end)\n",
    "    return total\n",
    "\n",
    "\n",
    "def estimate_cell_size_from_layout(df: pd.DataFrame) -> float:\n",
    "    \"\"\"Ước lượng kích thước cell để rasterize layout thành lưới (phục vụ vẽ PNG).\"\"\"\n",
    "    vals = []\n",
    "    arr = df[[\"x\", \"y\", \"width\", \"height\"]].values\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        x0, y0, w0, h0 = arr[i]\n",
    "        x0b, y0b = x0 + w0, y0 + h0\n",
    "        for j in range(i + 1, n):\n",
    "            x1, y1, w1, h1 = arr[j]\n",
    "            x1b, y1b = x1 + w1, y1 + h1\n",
    "            if not (y0b < y1 or y1b < y0):\n",
    "                gx = max(0, x0 - x1b, x1 - x0b)\n",
    "                if gx > 1:\n",
    "                    vals.append(gx)\n",
    "            if not (x0b < x1 or x1b < x0):\n",
    "                gy = max(0, y0 - y1b, y1 - y0b)\n",
    "                if gy > 1:\n",
    "                    vals.append(gy)\n",
    "    if vals:\n",
    "        return max(1, int(min(vals)) // 2)\n",
    "    min_dim = np.minimum(df[\"width\"], df[\"height\"])\n",
    "    return (\n",
    "        max(1, int(np.median(min_dim[min_dim > 0]) / 4)) if (min_dim > 0).any() else 5\n",
    "    )\n",
    "\n",
    "\n",
    "def rasterize_grid(df: pd.DataFrame, cell_size: float):\n",
    "    \"\"\"Chuyển layout (hình chữ nhật) thành lưới (grid id) để vẽ ảnh preview.\"\"\"\n",
    "    cats = list(df[\"Category\"].astype(str).unique())\n",
    "    name2id = {c: i + 1 for i, c in enumerate(cats)}\n",
    "    id2name = {v: k for k, v in name2id.items()}\n",
    "\n",
    "    x0, y0 = df[\"x\"].min(), df[\"y\"].min()\n",
    "    x1, y1 = (df[\"x\"] + df[\"width\"]).max(), (df[\"y\"] + df[\"height\"]).max()\n",
    "    pad_x, pad_y = int((x1 - x0) * PADDING_RATIO), int((y1 - y0) * PADDING_RATIO)\n",
    "    min_x, min_y = x0 - pad_x, y0 - pad_y\n",
    "    max_x, max_y = x1 + pad_x, y1 + pad_y\n",
    "\n",
    "    W = int(math.ceil((max_x - min_x) / cell_size))\n",
    "    H = int(math.ceil((max_y - min_y) / cell_size))\n",
    "    if W * H > 1e7:  # an toàn bộ nhớ\n",
    "        scale_factor = math.sqrt((W * H) / 1e7)\n",
    "        cell_size *= scale_factor\n",
    "        W = int(math.ceil((max_x - min_x) / cell_size))\n",
    "        H = int(math.ceil((max_y - min_y) / cell_size))\n",
    "\n",
    "    grid = np.zeros((H, W), dtype=np.int32)\n",
    "    for _, r in df.iterrows():\n",
    "        did = name2id[str(r[\"Category\"])]\n",
    "        gx0 = int(math.floor((r[\"x\"] - min_x) / cell_size))\n",
    "        gx1 = int(math.ceil((r[\"x\"] + r[\"width\"] - min_x) / cell_size))\n",
    "        gy0 = int(math.floor((r[\"y\"] - min_y) / cell_size))\n",
    "        gy1 = int(math.ceil((r[\"y\"] + r[\"height\"] - min_y) / cell_size))\n",
    "        grid[gy0:gy1, gx0:gx1] = did\n",
    "\n",
    "    meta = {\"min_x\": min_x, \"min_y\": min_y, \"cell_size\": cell_size, \"W\": W, \"H\": H}\n",
    "    return grid, name2id, id2name, meta\n",
    "\n",
    "\n",
    "def visualize_pretty(df_layout: pd.DataFrame, out_png: Path) -> None:\n",
    "    \"\"\"Vẽ preview layout ra PNG (label tự động, giữ Entrance/Cashier nguyên vị trí).\"\"\"\n",
    "    cell = estimate_cell_size_from_layout(df_layout)\n",
    "    grid, name2id, id2name, meta = rasterize_grid(df_layout, cell)\n",
    "\n",
    "    H, W = grid.shape\n",
    "    unique_ids = np.unique(grid)\n",
    "    max_id = int(unique_ids.max()) if len(unique_ids) > 0 else 0\n",
    "\n",
    "    colors = [\"#FFFFFF\"] + [\n",
    "        plt.cm.get_cmap(\"tab20\", max(1, max_id))(i) for i in range(max_id)\n",
    "    ]\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = list(range(0, max_id + 2))\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    fig_w = min(30, 18 * (W / max(1, H)))\n",
    "    fig_h = min(30, 18)\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "    ax.imshow(grid, cmap=cmap, norm=norm, interpolation=\"none\")\n",
    "\n",
    "    for did in np.unique(grid[grid > 0]):\n",
    "        ys, xs = np.where(grid == did)\n",
    "        if len(xs) == 0:\n",
    "            continue\n",
    "        cx, cy = np.mean(xs), np.mean(ys)\n",
    "        name = id2name.get(did, f\"ID {did}\")\n",
    "        region_color = cmap(norm(did))\n",
    "        lum = (\n",
    "            0.299 * region_color[0] + 0.587 * region_color[1] + 0.114 * region_color[2]\n",
    "        )\n",
    "        txt_color = \"white\" if lum < 0.5 else \"black\"\n",
    "        w = xs.max() - xs.min() + 1\n",
    "        h = ys.max() - ys.min() + 1\n",
    "        rot = 90 if h > w * 1.6 and len(name) > 5 else 0\n",
    "        fontsize = max(6, min(11, int(np.sqrt(w * h) / max(1, len(name)) * 4)))\n",
    "        ax.text(\n",
    "            cx,\n",
    "            cy,\n",
    "            name,\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            color=txt_color,\n",
    "            fontsize=fontsize,\n",
    "            rotation=rot,\n",
    "            weight=\"bold\",\n",
    "        )\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Layout mới (preview dạng grid từ PPTX + flags từ CSV)\",\n",
    "        fontsize=14,\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False,\n",
    "    )\n",
    "    plt.savefig(out_png, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def apply_layout_to_ppt(\n",
    "    df_new: pd.DataFrame, prs_in: Presentation, out_pptx: Path\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Ghi lại nhãn Category cho CÁC SLOT BÀY HÀNG trên PPTX (không động vào Entrance/Cashier).\n",
    "    Tô màu theo category để dễ phân biệt.\n",
    "    \"\"\"\n",
    "    cats = list(\n",
    "        df_new.loc[~(df_new[\"is_entrance\"] | df_new[\"is_cashier\"]), \"Category\"]\n",
    "        .astype(str)\n",
    "        .unique()\n",
    "    )\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", max(1, len(cats)))\n",
    "    cat2rgb = {\n",
    "        c: (int(r * 255), int(g * 255), int(b * 255))\n",
    "        for i, c in enumerate(cats)\n",
    "        for r, g, b, _ in [cmap(i)]\n",
    "    }\n",
    "\n",
    "    df_place = df_new[~(df_new[\"is_entrance\"] | df_new[\"is_cashier\"])].sort_values(\n",
    "        [\"slide_idx\", \"shape_idx\"]\n",
    "    )\n",
    "    new_texts = df_place[\"Category\"].tolist()\n",
    "    shapes_sorted = df_place[\"shape_obj\"].tolist()\n",
    "\n",
    "    for sh, new_cat in zip(shapes_sorted, new_texts):\n",
    "        sh.text_frame.clear()\n",
    "        p = sh.text_frame.paragraphs[0]\n",
    "        run = p.add_run()\n",
    "        run.text = str(new_cat)\n",
    "        run.font.size = Pt(10)\n",
    "        run.font.bold = True\n",
    "        if new_cat in cat2rgb:\n",
    "            r, g, b = cat2rgb[new_cat]\n",
    "            sh.fill.solid()\n",
    "            sh.fill.fore_color.rgb = RGBColor(r, g, b)\n",
    "            if sh.line:\n",
    "                sh.line.color.rgb = RGBColor(40, 40, 40)\n",
    "                sh.line.width = Pt(0.75)\n",
    "\n",
    "    prs_in.save(out_pptx)\n",
    "\n",
    "\n",
    "def save_and_visualize(\n",
    "    input_data: Dict,\n",
    "    assign_map: Dict[str, int],\n",
    "    output_layout_csv: str = \"layout_new.csv\",\n",
    "    output_preview_png: str = \"layout_new.png\",\n",
    "    output_pptx: str = \"layout_new.pptx\",\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Áp mapping tối ưu vào dataframe gốc (chỉ slot bày hàng), rồi xuất CSV/PNG/PPTX.\n",
    "    Benchmark đường đi dựa trên baskets (nếu có).\n",
    "    \"\"\"\n",
    "    df = input_data[\"df\"].copy()\n",
    "    slots = input_data[\"slots\"]\n",
    "    prs = input_data[\"prs\"]\n",
    "    entr_xy = input_data[\"entr_xy\"]\n",
    "    cash_xy = input_data[\"cash_xy\"]\n",
    "    baskets = input_data[\"baskets\"]\n",
    "\n",
    "    # cập nhật Category cho các slot bày hàng theo best_assign (giữ nguyên Entrance/Cashier)\n",
    "    slotidx_to_cat = {assign_map[c]: c for c in input_data[\"layout_cats\"]}\n",
    "\n",
    "    for _, row in slots.iterrows():\n",
    "        orig_idx = int(row[\"orig_idx\"])  # <— dùng orig_idx để trỏ đúng hàng ở df\n",
    "        slot_idx = int(row[\"slot_idx\"])\n",
    "        new_cat = slotidx_to_cat.get(slot_idx, row[\"Category\"])\n",
    "        df.at[orig_idx, \"Category\"] = new_cat  # <— chỉ cập nhật các slot bày hàng\n",
    "\n",
    "    # (Tuỳ chọn) An toàn: khẳng định Entrance/Cashier không đổi\n",
    "    entr_row = input_data[\"df\"].loc[input_data[\"df\"][\"is_entrance\"]].iloc[0]\n",
    "    cash_row = input_data[\"df\"].loc[input_data[\"df\"][\"is_cashier\"]].iloc[0]\n",
    "    assert (\n",
    "        df.loc[entr_row.name, \"Category\"] == entr_row[\"Category\"]\n",
    "    ), \"Entrance bị ghi đè!\"\n",
    "    assert (\n",
    "        df.loc[cash_row.name, \"Category\"] == cash_row[\"Category\"]\n",
    "    ), \"Cashier bị ghi đè!\"\n",
    "\n",
    "    # Xuất file\n",
    "    (OUTPUT_DATA_DIR / output_layout_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(OUTPUT_DATA_DIR / output_layout_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    visualize_pretty(df, OUTPUT_DATA_DIR / output_preview_png)\n",
    "    apply_layout_to_ppt(df, prs, OUTPUT_DATA_DIR / output_pptx)\n",
    "\n",
    "    # Benchmark (giữ nguyên Entrance/Cashier)\n",
    "    orig_cat2xy = {\n",
    "        str(r[\"Category\"]): (r[\"cx\"], r[\"cy\"])\n",
    "        for _, r in input_data[\"df\"].iterrows()\n",
    "        if not (r[\"is_entrance\"] or r[\"is_cashier\"])\n",
    "    }\n",
    "    new_cat2xy = {\n",
    "        str(r[\"Category\"]): (r[\"cx\"], r[\"cy\"])\n",
    "        for _, r in df.iterrows()\n",
    "        if not (r[\"is_entrance\"] or r[\"is_cashier\"])\n",
    "    }\n",
    "\n",
    "    def avg_path_length(cat2xy):\n",
    "        sample_b = (\n",
    "            baskets\n",
    "            if len(baskets) <= 500\n",
    "            else random.sample(baskets, 500) if baskets else []\n",
    "        )\n",
    "        lens = []\n",
    "        for b in sample_b:\n",
    "            pts = [cat2xy[c] for c in b if c in cat2xy]\n",
    "            lens.append(greedy_path_length(pts, entr_xy, cash_xy, dist_fn=manhattan))\n",
    "        return np.mean(lens) if lens else float(\"nan\")\n",
    "\n",
    "    base_L = avg_path_length(orig_cat2xy)\n",
    "    new_L = avg_path_length(new_cat2xy)\n",
    "    improve = (\n",
    "        (base_L - new_L) / base_L * 100\n",
    "        if (base_L and not math.isnan(base_L) and base_L > 0)\n",
    "        else float(\"nan\")\n",
    "    )\n",
    "\n",
    "    print(f\"Base path length: {base_L:.2f}\")\n",
    "    print(f\"New path length: {new_L:.2f}\")\n",
    "    print(f\"Improvement: {improve:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"df_new\": df,\n",
    "        \"base_length\": base_L,\n",
    "        \"new_length\": new_L,\n",
    "        \"improvement\": improve,\n",
    "    }\n",
    "\n",
    "\n",
    "save_and_visualize(\n",
    "    input_data,\n",
    "    assign_map,\n",
    "    output_layout_csv=\"layout_new.csv\",\n",
    "    output_preview_png=\"layout_new.png\",\n",
    "    output_pptx=\"layout_new.pptx\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
